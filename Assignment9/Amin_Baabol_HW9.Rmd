---
title: "9 Additional Graphs Homework"
author: "Amin Baabol"
date: "07/27/2020"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

# General Instructions

There are six exercises below. You are required to provide five solutions, with the same options for choosing languages as with the last exercise. You can provide solutions in two languages for one exercise only (for example, Ex. 1,2,3,5 in R and Ex. 1 in SAS is acceptable, Ex. 1,2,3 in SAS and Ex. 1,2 in R is not)

For this exercise, you may use whatever graphics library you desire.

# Exercise 1.

Load the `ncaa2018.csv` data set and create histograms, QQ-norm and box-whisker plots for `ELO`. Add a title to each plot, identifying the data.

```{r}
#loading ncaa2018.csv data set
ncaa2018csv = read.table("~/Desktop/work/GradSchool/Summer2020/STATS600/week7/ncaa2018.csv",header = T,sep = ",")

#Histrogram
hist(ncaa2018csv$ELO, xlab = "ELO", main = "ELO Histrogram")


# QQ-Norm
qqnorm(ncaa2018csv$ELO, main = "Normal QQ plot")

# Box-Whisker 
boxplot(ncaa2018csv$ELO, main = "Box-Whisker", ylab = "ELO")
```

### Part b

A common recommendation to address issues of non-normality is to transform data to correct for skewness. One common transformation is the log transform. 

Transform `ELO` to `log(ELO)` and produce histograms, box-whisker and qqnorm plots of the transformed values. Are the transformed values more or less skewed than the original? You might calculate skewness and kurtosis values as in Homework 6, Exercise 2.

```{r}
#Histrogram
hist(log(ncaa2018csv$ELO), xlab = "ELO", main = "Log-Transformed Histrogram ")

# QQ plot
qqnorm(log(ncaa2018csv$ELO), main = "Log-Transformed QQ-norm")

# box-whisker plot
boxplot(log(ncaa2018csv$ELO), main = "Log-Transformed Box-whisker", ylab = "ELO")

```

# Exercise 2.

Review Exercise 2, Homework 6, where you calculated skewness and kurtosis. The reference for this exercise, https://www.itl.nist.gov/div898/handbook/eda/section3/eda35b.htm, 

> The following example shows histograms for 10,000 random numbers generated from a normal, a double exponential, a Cauchy, and a Weibull distribution.

We will reproduce the histograms for these samples, and add qqnorm and box-whisker plots.

## Part a

Use the code below from lecture to draw 10000 samples from the normal distribution.

```{r}
norm.sample <- rnorm(10000, mean=0, sd=1)

```


Look up the corresponding `r*` functions in R for the Cauchy distribution (use location=0, scale=1), and the Weibull distribution (use shape = 1.5). For the double exponential, use you can use the `*laplace` functions from the `rmutil` library, or you can use `rexp(10000) - rexp(10000)`

Draw 10000 samples from each of these distributions. Calculate skewness and kurtosis for each sample. You may use your own function, or use the `moments` library.

```{r,eval=TRUE}
cauchy.distro<- rcauchy(1:1000, location = 0, scale = 1)
weibull.distro <- rweibull(1:1000, shape = 1.5)
rexp10k <- rexp(1000) - rexp(1000)


#install.packages(moments)
library(moments)

#Normal Distribution Skewness and Kurtosis
skewness1 <- round(skewness(norm.sample, na.rm = TRUE),2)
kurtosis1 <- round(kurtosis(norm.sample, na.rm = TRUE),2)
skewness1
kurtosis1

#Cauchy Distribution Skewness and Kurtosis
skewness2 <- round(skewness(cauchy.distro, na.rm = TRUE),2)
kurtosis2 <- round(kurtosis(cauchy.distro, na.rm = TRUE),2)
skewness2
kurtosis2


#Weibull Distribution Skewness and Kurtosis

skewness3 <- round(skewness(weibull.distro, na.rm = TRUE),2)
kurtosis3 <- round(kurtosis(weibull.distro, na.rm = TRUE),2)
skewness3
kurtosis3


#Exponential Distribution Skewness and Kurtosis
skewness4 <- round(skewness(rexp10k, na.rm = TRUE),2)
kurtosis4 <- round(kurtosis(rexp10k, na.rm = TRUE),2)
skewness4
kurtosis4


```

## Part b

Plot the histograms for each distribution. Use `par(mfrow=c(2,2))` in your code chunk to combine the four histogram in a single plot. Add titles to the histograms indicating the distribution. Set the x-axis label to show the calculated skewness and kurtosis, i.e. `skewness = ####, kurtosis = ####`

```{r,eval=TRUE}
par(mfrow=c(2,2))
hist(norm.sample, xlab = paste0("skewness = ", skewness1 , ", kurtosis = ", kurtosis1), main = "Normal Distribution")
hist(cauchy.distro, xlab = paste0("skewness = ", skewness2 , ", kurtosis = ", kurtosis2), main = "Cauchy Distribution")
hist(weibull.distro, xlab = paste0("skewness = ", skewness3 , ", kurtosis = ", kurtosis3), main = "Weibull Distribution")
hist(rexp10k, xlab = paste0("skewness = ", skewness4 , ", kurtosis = ", kurtosis4), main = "Exponential Distribution")
```

## Part c
Repeat Part b, but with QQ-norm plots.

```{r,eval=TRUE}
par(mfrow=c(2,2))
qqnorm(norm.sample, xlab = paste0("skewness = ", skewness1 , ", kurtosis = ", kurtosis1), main = "Normal Distribution")
qqnorm(cauchy.distro, xlab = paste0("skewness = ", skewness2 , ", kurtosis = ", kurtosis2), main = "Cauchy Distribution")
qqnorm(weibull.distro, xlab = paste0("skewness = ", skewness3 , ", kurtosis = ", kurtosis3), main = "Weibull Distribution")
qqnorm(rexp10k, xlab = paste0("skewness = ", skewness4 , ", kurtosis = ", kurtosis4), main = "Exponential Distribution")
```


## Part d

Repeat Part b, but with box-whisker plots.

```{r,eval=TRUE}
par(mfrow=c(2,2))
boxplot(norm.sample, xlab = paste0("skewness = ", skewness1 , ", kurtosis = ", kurtosis1), main = "Normal Distribution")
boxplot(cauchy.distro, xlab = paste0("skewness = ", skewness2 , ", kurtosis = ", kurtosis2), main = "Cauchy Distribution")
boxplot(weibull.distro, xlab = paste0("skewness = ", skewness3 , ", kurtosis = ", kurtosis3), main = "Weibull Distribution")
boxplot(rexp10k, xlab = paste0("skewness = ", skewness4 , ", kurtosis = ", kurtosis4), main = "Exponential Distribution")
```


Hints for SAS. If you create the samples in IML, use 
```
Normal = j(1, 10000, .);
call randgen(Normal, "NORMAL", 0, `);
```

You can generate samples in the data step using
```
do i = 1 to 10000;
  Normal = rand('NORMAL',0,1);
  output;
end;
```

RAND doesn't provide a Laplace option, but you can create samples from this distribution by
```
rand('EXPONENTIAL')-rand('EXPONENTIAL');
```

To group multiple plots, use
```
ods graphics / width=8cm height=8cm;
ods layout gridded columns=2;
ods region;
 ... first plot

ods region;
 ... second plot

ods layout end;
```

You might need to include
```
ods graphics off;

ods graphics on;
ODS GRAPHICS / reset=All;
```
to return the SAS graphics output to normal.

## Exercise 3.

We will create a series of graphs illustrating how the Poisson distribution approaches the normal distribution with large $\lambda$. We will iterate over a sequence of `lambda`, from 2 to 64, doubling `lambda` each time. For each 'lambda' draw 1000 samples from the Poisson distribution. 

Calculate the skewness of each set of samples, and produce  histograms, QQ-norm and box-whisker plots. You can use `par(mfrow=c(1,3))` to display all three for one `lambda` in one line. Add `lambda=##` to the title of the histogram, and `skewness=##` to the title of the box-whisker plot.

## Part b. 

Remember that `lambda` represents the mean of a discrete (counting) variable. At what size mean is Poisson data no longer skewed, relative to normally distributed data? You might run this 2 or 3 times, with different seeds; this number varies in my experience.

```{r,fig.width=12}
set.seed(54321)
par(mfrow=c(1,3))
lambda <- 2
rpois <- {}


while(lambda <= 64){
val <- rpois(1000, lambda = lambda)
skew <- round(skewness(val, na.rm = TRUE),2)
rpois[lambda-1] <- skewness(val)

# attaching all three plots together
par(mfrow=c(1,3))

# histogram
hist(val, main = paste0("Histogram for Poisson Distribution = ", lambda))
# QQ-norm
qqnorm(val, main = "Normal QQ plot for Poisson Distribution")
# box-whisker 
boxplot(val, main = paste0("Box-whisker for Poisson Distribution with skewness = ", skew), ylab = "values")
lambda <- lambda*2}

plot(rpois,ylab="Poisson Distribution")

```

If you do this in SAS, create a data table with data columns each representing a different $\mu$. You can see combined histogram, box-whisker and QQ-norm, for all columns, by calling

```
proc univariate data=Distributions plot;
run;
```

At what $\mu$ is skewness of the Poisson distribution small enough to be considered normal?


# Exercise 4

## Part a
Write a function that accepts a vector `vec`, a vector of integers, a main axis label and an x axis label. This function should 
1. iterate over each element $i$ in the vector of integers 
2. produce a histogram for `vec` setting the number of bins in the histogram to $i$
3. label main and x-axis with the specified parameters. 
4. label the y-axis to read `Frequency, bins =` and the number of bins.

Hint:
You can simplify this function by using the parameter `...` - see `?plot` or ?`hist`

## Part b
Test your function with the `hidalgo` data set (see below), using bin numbers 12, 36, and 60. You should be able to call your function with something like
```{r}

hidalgo.data = read.table("~/Desktop/work/GradSchool/Summer2020/STATS600/week9/hidalgo.dat",header = T,sep = ",")
bin <- c(12,36,60)
hidalgo <- hidalgo.data[,1]
i=1

plot.histograms <- function(hidalgo, bin, main, xlab){
  par(mfrow=c(1,length(bin)))
  for(i in 1:length(bin)){
  print(hist(hidalgo, breaks = bin[i],  main = main, xlab = xlab, ylab = paste0('Frequency, bins = ', bin[i])))}}

plot.histograms(hidalgo,bin, main="1872 Hidalgo issue",xlab= "Thickness (mm)")

```
to plot three different histograms of the `hidalgo` data set.


If you do this in SAS, write a macro that accepts a table name, a column name, a list of integers, a main axis label and an x axis label. This macro should scan over each element in the list of integers and produce a histogram for each integer value, setting the bin count to the element in the input list, and labeling main and x-axis with the specified parameters. You should label the y-axis to read `Frequency, bins =` and the number of bins.

Test your macro with the `hidalgo` data set (see below), using bin numbers 12, 36, and 60. You should be able to call your macro with something like
```
%plot_histograms(hidalgo, y, 12 36 60, main="1872 Hidalgo issue", xlabel="Thickness (mm)");
```
to plot three different histograms of the `hidalgo` data set.

Hint:
Assume `12 36 60` resolve to a single macro parameter and use `%scan`. Your macro definition can look something like
```
%macro plot_histograms(table_name, column_name, number_of_bins, main="Main", xlabel="X Label")
```

## Data
The `hidalgo` data set is in the file `hidalgo.dat` These data consist of paper thickness measurements of stamps from the 1872 Hidalgo issue of Mexico. This data set is commonly used to illustrate methods of determining the number of components in a mixture (in this case, different batches of paper). See https://www.jstor.org/stable/2290118,  
https://books.google.com/books?id=1CuznRORa3EC&lpg=PA95&pg=PA94#v=onepage&q&f=false and https://books.google.com/books?id=c2_fAox0DQoC&pg=PA180&lpg=PA180&f=false
.

Some analysis suggest there are three different mixtures of paper used to produce the 1872 Hidalgo issue; other analysis suggest seven. Why do you think there might be disagreement about the number of mixtures?

##comments

I think it might be due to the paper thiclness variations


# Exercise 5.

We've been working with data from Wansink and Payne, Table 1:

### Reproducing part of Wansink Table 1


Measure | 1936 | 1946 | 1951 | 1963 | 1975 | 1997 | 2006 
:-------|-----:|-----:|-----:|-----:|-----:|-----:|-----:
calories per recipe (SD) | 2123.8 (1050.0) | 2122.3 (1002.3) | 2089.9 (1009.6) | 2250.0 (1078.6) | 2234.2 (1089.2) | 2249.6 (1094.8) | 3051.9 (1496.2)
calories per serving (SD) | 268.1 (124.8) | 271.1 (124.2) | 280.9 (116.2)  | 294.7 (117.7) | 285.6 (118.3) | 288.6 (122.0) | **384.4** (168.3)
servings per recipe (SD) | 12.9 (13.3) | 12.9 (13.3) | 13.0 (14.5) | 12.7 (14.6) | 12.4 (14.3) | 12.4 (14.3) | 12.7 (13.0)


However, in Homework 2, we also considered the value given in the text

> The resulting increase of 168.8 calories (from 268.1 calories ... to **436.9** calories ...) represents a 63.0% increase ... in calories per serving.

There is a discrepancy between two values reported for calories per serving, 2006. We will use graphs to attempt to determine which value is most consistent.

First, consider the relationship between Calories per Serving and Calories per Recipe:

```
Calories per Serving = Calories per Recipe / Servings per Recipe
```

Since `Servings per Recipe` is effectively constant over time (12.4-13.0), we can assume the relationship between `Calories per Serving` and `Calories per Recipe` is linear,

$$
\text{Calories per Serving} = \beta_0 + \beta_1 \times \text{Calories per Recipe}
$$
with $\text{Servings per Recipe} = 1/\beta_1$

We will fit a linear model, with `Calories per Recipe` as the independent variable against two sets of values for `Calories per Serving`, such that

- Assumption 1. The value in the table ($384.4$) is correct.
- Assumption 2. The value in the text ($436.9$) is correct.

We use the data:

```{r}
Assumptions.dat <- data.frame(
  CaloriesPerRecipe = c(2123.8, 2122.3, 2089.9, 2250.0, 2234.2, 2249.6, 3051.9),
  Assumption1 = c(268.1, 271.1, 280.9, 294.7, 285.6, 288.6, 384.4),
  Assumption2 = c(268.1, 271.1, 280.9, 294.7, 285.6, 288.6, 436.9))
```

and fit linear models
```{r}
Assumption1.lm <- lm(Assumption1 ~ CaloriesPerRecipe,data=Assumptions.dat)
Assumption2.lm <- lm(Assumption2 ~ CaloriesPerRecipe,data=Assumptions.dat)
summary(Assumption1.lm)
summary(Assumption2.lm)
```

### Part a.

Plot the regression. Use points to plot `Assumption1` vs `CaloriesPerRecipe`, and `Assumption2` vs `CaloriesPerRecipe`, on the same graph. Add lines (i.e. `abline`) to show the fit from the regression. Use different colors for the two assumptions.  Which of the two lines appears to best explain the data? 

```{r}
attach(Assumptions.dat)
par(mfrow=c(1,1))
plot(Assumption1~CaloriesPerRecipe, cex = 1.5, type = 'p', col = 'red')
abline(Assumption1.lm)
points(Assumption2~CaloriesPerRecipe, cex = 1.5, col = 'blue')
abline(Assumption2.lm)
```

### Part b.

Produce diagnostic plots plots of the residuals from both linear models (in R, use `residuals(Assumption1.lm)`). qqnorm or box-whisker plots will probably be the most effective; there are too few points for a histogram. 

Use the code below to place two plots, side by side. You can produce more than one pair of plots, if you wise.

```{r,fig.width=8,fig.height=5}
#Box-whisker plots
par(mfrow=c(1,2))
boxplot(residuals(Assumption1.lm), main = "Assumption1" ) 
boxplot(residuals(Assumption2.lm), main = "Assumption2" )
```

```{r,fig.width=8,fig.height=5}
#QQnorm plots
par(mfrow=c(1,2))
qqnorm(residuals(Assumption1.lm), main = "Assumption1" )
qqline(residuals(Assumption1.lm))
qqnorm(residuals(Assumption2.lm), main = "Assumption2" )
qqline(residuals(Assumption2.lm))
```

From these plots, which assumption is most likely correct? That is, which assumption produces a linear model that least violates assumptions of normality of the residual errors? Which assumption produces outliers in the residuals?

I've included similar data and linear models for SAS in the SAS template. If you choose SAS, you will need to modify the PROC GLM code to produce the appropriate diagnostic plots.
###comments
Assumption 2 has quiet a few anomalies which leads me to think assumption 1 is correct since its plot is within margin.